{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marsggbo/AutoMLDemos/blob/master/ch7/RandomNAS_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3rm2g1DCTXG6"
      },
      "source": [
        "# Install Dependencies and Import Modules\n",
        "\n",
        "You shoud restart the runtime after running the following pip commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zeLCIHEB-mU3",
        "outputId": "f4125680-3e03-4813-91d2-df647bdfed31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hyperbox\n",
            "  Downloading hyperbox-1.3.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.2\n",
            "  Downloading hydra_core-1.3.1-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning>=1.5\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 KB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.2->hyperbox) (5.10.2)\n",
            "Collecting omegaconf<2.4,>=2.2\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.2->hyperbox) (21.3)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5->hyperbox) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5->hyperbox) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5->hyperbox) (4.4.0)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0\n",
            "  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting tensorboardX>=2.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5->hyperbox) (1.13.0+cu116)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5->hyperbox) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.5->hyperbox) (2022.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (2.25.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (3.8.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->hydra-core>=1.2->hyperbox) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning>=1.5->hyperbox) (3.19.6)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core>=1.2->hyperbox) (3.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (6.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.5->hyperbox) (2022.12.7)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=abf53d0cb4e2ca82ae1b1469566804647e2f537f6106cc39ccc02d6dc7e79f8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, tensorboardX, omegaconf, torchmetrics, lightning-utilities, hydra-core, pytorch-lightning, hyperbox\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.1 hyperbox-1.3.0 lightning-utilities-0.5.0 omegaconf-2.3.0 pytorch-lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rich\n",
            "  Downloading rich-13.1.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich) (4.4.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.13.0-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a2f7ec451892daf1f59d7af670550eb6f7fb19ed280c51453e7603b15884f504\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, commonmark, urllib3, smmap, setproctitle, rich, loguru, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.30 commonmark-0.9.1 docker-pycreds-0.4.0 gitdb-4.0.10 loguru-0.6.0 pathtools-0.1.2 rich-13.1.0 sentry-sdk-1.13.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.9\n"
          ]
        }
      ],
      "source": [
        "!pip install hyperbox==1.3.1\n",
        "!pip install pytorch-lightning==1.8.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gVodUEvA-15J"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from hyperbox.mutables import spaces, ops\n",
        "from hyperbox.mutator import RandomMutator\n",
        "from hyperbox.networks.base_nas_network import BaseNASNetwork\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihXr6X6EMEW6"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omz8YgPUKrOl",
        "outputId": "b9619caf-8898-4e4a-bdcd-56082ee0ac85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=64, dry_run=False, epochs=2, gamma=0.7, log_interval=100, lr=1.0, no_cuda=False, no_mps=False, save_model=False, seed=1, test_batch_size=1000)\n"
          ]
        }
      ],
      "source": [
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')    \n",
        "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
        "                        help='input batch size for testing (default: 1000)')\n",
        "    parser.add_argument('--epochs', type=int, default=2, metavar='N',\n",
        "                        help='number of epochs to train (default: 14)')\n",
        "    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
        "                        help='learning rate (default: 1.0)')\n",
        "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
        "                        help='Learning rate step gamma (default: 0.7)')\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                        help='disables CUDA training')\n",
        "    parser.add_argument('--no-mps', action='store_true', default=False,\n",
        "                        help='disables macOS GPU training')\n",
        "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
        "                        help='quickly check a single pass')\n",
        "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
        "                        help='how many batches to wait before logging training status')\n",
        "    parser.add_argument('--save-model', action='store_true', default=False,\n",
        "                        help='For Saving the current Model')\n",
        "    args = parser.parse_args(args=[])\n",
        "    return args\n",
        "\n",
        "args = get_args()\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGjv4HKUCsJh"
      },
      "source": [
        "# Neural Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r-nXoivP_P8c"
      },
      "outputs": [],
      "source": [
        "class Net(BaseNASNetwork):\n",
        "    def __init__(self, mask=None):\n",
        "        super(Net, self).__init__(mask)\n",
        "        self.conv1 = spaces.OperationSpace(candidates=[\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.Conv2d(1, 32, 5, 1, 2),\n",
        "            nn.Conv2d(1, 32, 7, 1, 3)\n",
        "        ], key='conv1', mask=self.mask)\n",
        "        \n",
        "        self.conv2 = spaces.OperationSpace(candidates=[\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.Conv2d(32, 64, 5, 1, 2),\n",
        "            nn.Conv2d(32, 64, 7, 1, 3)\n",
        "        ], key='conv2', mask=self.mask)\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(12544, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptrg32svEvVm"
      },
      "source": [
        "test `Net`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSq8j3fYCvP2",
        "outputId": "05b3aa62-2e33-497c-83ea-95d5358149ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arch={'conv1': tensor([False,  True, False]), 'conv2': tensor([ True, False, False])}\n",
            "Net(\n",
            "  (conv1): OperationSpace(\n",
            "    (candidates): ModuleList(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (2): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    )\n",
            "  )\n",
            "  (conv2): OperationSpace(\n",
            "    (candidates): ModuleList(\n",
            "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    )\n",
            "  )\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "torch.Size([2, 10])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(2,1,28,28)\n",
        "net = Net()\n",
        "rm = RandomMutator(net)\n",
        "rm.reset()\n",
        "y = net(x)\n",
        "arch = rm._cache\n",
        "print(f\"arch={arch}\")\n",
        "print(net)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRahAjsB-qtr"
      },
      "source": [
        "# Prepare MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhwrzc2e-0QH",
        "outputId": "f44d097d-6bec-430b-fa2d-ee5d8779cd93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "train_set = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
        "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
        "test_set = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
        "print(len(train_set))\n",
        "print(len(val_set))\n",
        "print(len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6f99EsOE332",
        "outputId": "d03b4dc8-aeee-40d0-9287-8c9fb3146532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "x,y = train_set[0]\n",
        "print(type(x), x.shape)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqSFBL8jUkFa",
        "outputId": "6ff0beeb-1188-46df-a2ac-67d52cf02b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "x,y = test_set[0]\n",
        "print(type(x), x.shape)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NaXJ5Pqq_YpW"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(args.seed)\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "train_kwargs = {'batch_size': args.batch_size, 'shuffle': True}\n",
        "test_kwargs = {'batch_size': args.test_batch_size, 'shuffle': False}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True\n",
        "                   }\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,**train_kwargs)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, **test_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, **test_kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMxBYZ2O_tVn"
      },
      "source": [
        "## test dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmoumm6t_cCW",
        "outputId": "569e8ae0-8465-411f-b92e-b013d44cde6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 28, 28]) torch.Size([1000])\n",
            "torch.Size([1000, 1, 28, 28]) torch.Size([1000])\n",
            "torch.Size([1000, 1, 28, 28]) torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "for batch_id, (imgs, labels) in enumerate(test_loader):\n",
        "    if batch_id > 2:\n",
        "        break\n",
        "    print(imgs.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZYuwZ2RKlUh"
      },
      "source": [
        "# Train & Test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "X8kkTVbyFRhz"
      },
      "outputs": [],
      "source": [
        "def train(args, model, mutator, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if mutator is not None:\n",
        "            mutator.reset()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            if args.dry_run:\n",
        "                break\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, verbose=True):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    if verbose:\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), accuracy))\n",
        "    return test_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT4_Ru6uMHvE"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nz09sgUPlg7",
        "outputId": "fdf3ab04-5722-467a-ec0f-26b4615288da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space includes 9 candidate models.\n"
          ]
        }
      ],
      "source": [
        "# build search space for evaluation\n",
        "search_space = []\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        index1 = torch.tensor(i)\n",
        "        index2 = torch.tensor(j)\n",
        "        arch = {\n",
        "            'conv1': F.one_hot(index1, num_classes=3).view(-1).bool(),\n",
        "            'conv2': F.one_hot(index2, num_classes=3).view(-1).bool()\n",
        "        }\n",
        "        search_space.append(arch)\n",
        "print(f\"Search space includes {len(search_space)} candidate models.\")\n",
        "\n",
        "def mask_to_arch_str(mask: dict):\n",
        "    conv_names = np.array(['conv3x3', 'conv5x5', 'conv7x7'])\n",
        "    arch = ''\n",
        "    for key, one_hot_mask in mask.items():\n",
        "        arch += f\"{conv_names[one_hot_mask][0]}, \"\n",
        "    return arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_rs3XzYMuTf",
        "outputId": "6343ecc6-a4e3-44fe-89ab-b7fea6515d55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.299419\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.341070\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.166256\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.464842\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.293632\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.058981\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.087119\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.171333\n",
            "conv1-conv1:tensor([ True, False, False])\n",
            "conv2-conv2:tensor([ True, False, False])\n",
            " acc=96.88 loss=0.09886496887207032\n",
            "conv1-conv1:tensor([ True, False, False])\n",
            "conv2-conv2:tensor([False,  True, False])\n",
            " acc=95.59 loss=0.14767451248168945\n",
            "conv1-conv1:tensor([ True, False, False])\n",
            "conv2-conv2:tensor([False, False,  True])\n",
            " acc=96.16 loss=0.12815116500854493\n",
            "conv1-conv1:tensor([False,  True, False])\n",
            "conv2-conv2:tensor([ True, False, False])\n",
            " acc=96.86 loss=0.10230393753051757\n",
            "conv1-conv1:tensor([False,  True, False])\n",
            "conv2-conv2:tensor([False,  True, False])\n",
            " acc=96.56 loss=0.11312274322509766\n",
            "conv1-conv1:tensor([False,  True, False])\n",
            "conv2-conv2:tensor([False, False,  True])\n",
            " acc=95.85 loss=0.1292439224243164\n",
            "conv1-conv1:tensor([False, False,  True])\n",
            "conv2-conv2:tensor([ True, False, False])\n",
            " acc=96.94 loss=0.10101297073364258\n",
            "conv1-conv1:tensor([False, False,  True])\n",
            "conv2-conv2:tensor([False,  True, False])\n",
            " acc=96.92 loss=0.10152501525878906\n",
            "conv1-conv1:tensor([False, False,  True])\n",
            "conv2-conv2:tensor([False, False,  True])\n",
            " acc=96.07 loss=0.13193191375732422\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.201790\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.071605\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.095254\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.152597\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.161843\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.115128\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.355264\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.039433\n",
            "conv1-conv1:tensor([ True, False, False])\n",
            "conv2-conv2:tensor([ True, False, False])\n",
            " acc=97.62 loss=0.0730094741821289\n",
            "conv1-conv1:tensor([ True, False, False])\n",
            "conv2-conv2:tensor([False,  True, False])\n",
            " acc=97.86 loss=0.07295466613769531\n",
            "conv1-conv1:tensor([ True, False, False])\n",
            "conv2-conv2:tensor([False, False,  True])\n",
            " acc=97.41 loss=0.08225261383056641\n",
            "conv1-conv1:tensor([False,  True, False])\n",
            "conv2-conv2:tensor([ True, False, False])\n",
            " acc=97.65 loss=0.07613493041992188\n",
            "conv1-conv1:tensor([False,  True, False])\n",
            "conv2-conv2:tensor([False,  True, False])\n",
            " acc=97.95 loss=0.0702470428466797\n",
            "conv1-conv1:tensor([False,  True, False])\n",
            "conv2-conv2:tensor([False, False,  True])\n",
            " acc=97.54 loss=0.07512729034423828\n",
            "conv1-conv1:tensor([False, False,  True])\n",
            "conv2-conv2:tensor([ True, False, False])\n",
            " acc=97.59 loss=0.07643905372619629\n",
            "conv1-conv1:tensor([False, False,  True])\n",
            "conv2-conv2:tensor([False,  True, False])\n",
            " acc=97.75 loss=0.07339908027648925\n",
            "conv1-conv1:tensor([False, False,  True])\n",
            "conv2-conv2:tensor([False, False,  True])\n",
            " acc=97.61 loss=0.0811207878112793\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "rm = RandomMutator(model)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "history = {}\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, rm, device, train_loader, optimizer, epoch)\n",
        "    for mask in search_space:\n",
        "        rm.sample_by_mask(mask)\n",
        "        arch = model.arch\n",
        "        val_loss, val_acc = test(model, device, val_loader, False)\n",
        "        if arch not in history:\n",
        "            history[arch] = {\n",
        "                'mask': mask,\n",
        "                'acc': [val_acc],\n",
        "                'best_acc': val_acc\n",
        "            }\n",
        "        else:\n",
        "            history[arch]['acc'].append(val_acc)\n",
        "            history[arch]['best_acc'] = max(history[arch]['acc'])\n",
        "        print(f\"{arch} acc={val_acc} loss={val_loss}\")\n",
        "    scheduler.step()\n",
        "\n",
        "if args.save_model:\n",
        "    torch.save(model.state_dict(), \"mnist_cnn_nas.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZE8yrrvSeBu"
      },
      "source": [
        "# Export the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLsTJ1wDSdfM",
        "outputId": "6c481600-2aa9-49b5-bfcc-84b6970d2005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best arch is {'conv1': tensor([False,  True, False]), 'conv2': tensor([False,  True, False])} with acc 97.95.\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0\n",
        "mask = None\n",
        "for arch, info in history.items():\n",
        "    acc = info['best_acc']\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        mask = info['mask']\n",
        "\n",
        "print(f\"The best arch is {mask} with acc {best_acc}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJQssc_TOiKD",
        "outputId": "6a824445-2726-46fb-95bd-dcf62f1c4dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0528, Accuracy: 9832/10000 (98%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "subnet = model.build_subnet(mask).to(device)\n",
        "val_loss, val_acc = test(subnet, device, test_loader, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2jUOF1lPisk",
        "outputId": "cccf049c-9852-4d75-fb6c-f43f662e4e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): OperationSpace(key='conv1', value=Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)))\n",
            "  (conv2): OperationSpace(key='conv2', value=Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)))\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(subnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8qNQoY6Qeb7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP4tmu+nojreTknl5WWv+OO",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "hyperbox",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ea1dd16190af2e9c6e6bff77d922d58e6312e6b8c852baaf44a970c853dc93d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
